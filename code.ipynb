{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Preprocess the Data:\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'id', 'likes', 'query', 'replies', 'retweets', 'text',\n",
       "       'user', 'outage', 'outage_state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>likes</th>\n",
       "      <th>query</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>outage</th>\n",
       "      <th>outage_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-11-01 23:50:22</td>\n",
       "      <td>264152432282578945</td>\n",
       "      <td>1</td>\n",
       "      <td>EversourceMA OR EversourceNH OR VelcoVT OR nat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Tom May, CEO of Northeast Utilities, the paren...</td>\n",
       "      <td>EversourceMA</td>\n",
       "      <td>1</td>\n",
       "      <td>WV OH PA NJ CT MA NY DE MD IN KY MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-11-01 23:45:13</td>\n",
       "      <td>264151136792109056</td>\n",
       "      <td>0</td>\n",
       "      <td>EversourceMA OR EversourceNH OR VelcoVT OR nat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>@NYGovCuomo @lipanews @nationalgridus @nyseand...</td>\n",
       "      <td>readyforthenet</td>\n",
       "      <td>1</td>\n",
       "      <td>WV OH PA NJ CT MA NY DE MD IN KY MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-01 23:34:44</td>\n",
       "      <td>264148498352590849</td>\n",
       "      <td>1</td>\n",
       "      <td>EversourceMA OR EversourceNH OR VelcoVT OR nat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Some amazing video from the Wareham microburst...</td>\n",
       "      <td>EversourceMA</td>\n",
       "      <td>1</td>\n",
       "      <td>WV OH PA NJ CT MA NY DE MD IN KY MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-01 23:34:20</td>\n",
       "      <td>264148399190851584</td>\n",
       "      <td>0</td>\n",
       "      <td>EversourceMA OR EversourceNH OR VelcoVT OR nat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>@nationalgridus Call me if you need some help ...</td>\n",
       "      <td>sparky1000</td>\n",
       "      <td>1</td>\n",
       "      <td>WV OH PA NJ CT MA NY DE MD IN KY MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-01 23:31:56</td>\n",
       "      <td>264147793147490304</td>\n",
       "      <td>0</td>\n",
       "      <td>EversourceMA OR EversourceNH OR VelcoVT OR nat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Current PSNH statewide w/o power: 885. We're d...</td>\n",
       "      <td>EversourceNH</td>\n",
       "      <td>1</td>\n",
       "      <td>WV OH PA NJ CT MA NY DE MD IN KY MI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                  id  likes  \\\n",
       "0  2012-11-01 23:50:22  264152432282578945      1   \n",
       "1  2012-11-01 23:45:13  264151136792109056      0   \n",
       "2  2012-11-01 23:34:44  264148498352590849      1   \n",
       "3  2012-11-01 23:34:20  264148399190851584      0   \n",
       "4  2012-11-01 23:31:56  264147793147490304      0   \n",
       "\n",
       "                                               query  replies  retweets  \\\n",
       "0  EversourceMA OR EversourceNH OR VelcoVT OR nat...      1.0         3   \n",
       "1  EversourceMA OR EversourceNH OR VelcoVT OR nat...      0.0         0   \n",
       "2  EversourceMA OR EversourceNH OR VelcoVT OR nat...      0.0         1   \n",
       "3  EversourceMA OR EversourceNH OR VelcoVT OR nat...      0.0         0   \n",
       "4  EversourceMA OR EversourceNH OR VelcoVT OR nat...      1.0         8   \n",
       "\n",
       "                                                text            user  outage  \\\n",
       "0  Tom May, CEO of Northeast Utilities, the paren...    EversourceMA       1   \n",
       "1  @NYGovCuomo @lipanews @nationalgridus @nyseand...  readyforthenet       1   \n",
       "2  Some amazing video from the Wareham microburst...    EversourceMA       1   \n",
       "3  @nationalgridus Call me if you need some help ...      sparky1000       1   \n",
       "4  Current PSNH statewide w/o power: 885. We're d...    EversourceNH       1   \n",
       "\n",
       "                          outage_state  \n",
       "0  WV OH PA NJ CT MA NY DE MD IN KY MI  \n",
       "1  WV OH PA NJ CT MA NY DE MD IN KY MI  \n",
       "2  WV OH PA NJ CT MA NY DE MD IN KY MI  \n",
       "3  WV OH PA NJ CT MA NY DE MD IN KY MI  \n",
       "4  WV OH PA NJ CT MA NY DE MD IN KY MI  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38069"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outage\n",
       "1         20431\n",
       "0         17638\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"outage\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    500\n",
      "1    500\n",
      "Name: outage, dtype: int64\n",
      "0    2000\n",
      "1    2000\n",
      "Name: outage, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate samples for each class\n",
    "outage_samples = data[data['outage'] == 1]\n",
    "no_outage_samples = data[data['outage'] == 0]\n",
    "\n",
    "# Randomly sample 500 samples from each class for training data\n",
    "outage_training_samples = outage_samples.sample(n=500, random_state=42)\n",
    "no_outage_training_samples = no_outage_samples.sample(n=500, random_state=42)\n",
    "\n",
    "# Concatenate the samples from both classes for training data\n",
    "training_data = pd.concat([outage_training_samples, no_outage_training_samples])\n",
    "\n",
    "# Get the remaining samples for testing data\n",
    "outage_remaining_samples = outage_samples[~outage_samples.index.isin(outage_training_samples.index)]\n",
    "no_outage_remaining_samples = no_outage_samples[~no_outage_samples.index.isin(no_outage_training_samples.index)]\n",
    "\n",
    "# Randomly sample 2000 samples from each class for testing data\n",
    "outage_testing_samples = outage_remaining_samples.sample(n=2000, random_state=42)\n",
    "no_outage_testing_samples = no_outage_remaining_samples.sample(n=2000, random_state=42)\n",
    "\n",
    "# Concatenate the samples from both classes for testing data\n",
    "testing_data = pd.concat([outage_testing_samples, no_outage_testing_samples])\n",
    "\n",
    "# Verify the distribution\n",
    "print(training_data['outage'].value_counts())\n",
    "print(testing_data['outage'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_length_train = training_data.groupby('outage')['text'].apply(lambda x: x.str.len().mean())\n",
    "avg_length_test = testing_data.groupby('outage')['text'].apply(lambda x: x.str.len().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outage\n",
      "0    101.496\n",
      "1     99.430\n",
      "Name: text, dtype: float64\n",
      "100.463\n"
     ]
    }
   ],
   "source": [
    "print(avg_length_train)\n",
    "print(avg_length_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outage\n",
      "0    100.8235\n",
      "1     99.2205\n",
      "Name: text, dtype: float64\n",
      "100.02199999999999\n"
     ]
    }
   ],
   "source": [
    "print(avg_length_test)\n",
    "print(avg_length_test.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def run_nlp_model(model_name, train_data, test_data):\n",
    "    \"\"\"\n",
    "    Run NLP model workflow for XGBoost, SVM, or Logistic Regression.\n",
    "    \n",
    "    Args:\n",
    "    - model_name (str): Name of the model ('xgboost', 'svm', or 'logistic').\n",
    "    - train_data (DataFrame): Training data with 'text' and 'outage' columns.\n",
    "    - test_data (DataFrame): Testing data with 'text' and 'outage' columns.\n",
    "    \"\"\"\n",
    "    # Extract labels from the 'outage' column for training and testing data\n",
    "    train_labels = train_data['outage']\n",
    "    test_labels = test_data['outage']\n",
    "    \n",
    "    # Preprocessing\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    train_features = vectorizer.fit_transform(train_data['text'])\n",
    "    test_features = vectorizer.transform(test_data['text'])\n",
    "    \n",
    "    # Model selection\n",
    "    if model_name == 'xgboost':\n",
    "        model = XGBClassifier()\n",
    "    elif model_name == 'svm':\n",
    "        model = SVC()\n",
    "    elif model_name == 'logistic':\n",
    "        model = LogisticRegression()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name. Choose from 'xgboost', 'svm', or 'logistic'.\")\n",
    "    \n",
    "    # Training\n",
    "    model.fit(train_features, train_labels)\n",
    "    \n",
    "    # Testing\n",
    "    predictions = model.predict(test_features)\n",
    "    \n",
    "    # Evaluation\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions)\n",
    "    recall = recall_score(test_labels, predictions)\n",
    "    f1 = f1_score(test_labels, predictions)\n",
    "    \n",
    "    # Print the evaluation metrics\n",
    "    print(\"Model:\", model_name)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: svm\n",
      "Accuracy: 0.6615\n",
      "Precision: 0.671443736730361\n",
      "Recall: 0.6325\n",
      "F1-score: 0.6513903192584963\n"
     ]
    }
   ],
   "source": [
    "# Call the function for SVM\n",
    "run_nlp_model('svm', training_data, testing_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: logistic\n",
      "Accuracy: 0.6535\n",
      "Precision: 0.652281746031746\n",
      "Recall: 0.6575\n",
      "F1-score: 0.6548804780876494\n"
     ]
    }
   ],
   "source": [
    "# Call the function for Logistic Regression\n",
    "run_nlp_model('logistic', training_data, testing_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: xgboost\n",
      "Accuracy: 0.6015\n",
      "Precision: 0.5881841876629018\n",
      "Recall: 0.677\n",
      "F1-score: 0.6294746629474663\n"
     ]
    }
   ],
   "source": [
    "# Call the function for XGBoost\n",
    "run_nlp_model('xgboost', training_data, testing_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
